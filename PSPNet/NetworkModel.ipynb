{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSPNet 네트워크 구성 및 구현:\n",
    "\n",
    "학습 목표:\n",
    "\n",
    "1. PSPNet 네트워크 구조를 모듈 단위로 이해한다.\n",
    "2. PSPNet을 구성하는 각 모듈의 역할을 이해한다.\n",
    "3. PSPNet 네트워크 클래스의 구현을 이해한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSPNet은 네 개의 모듈인 Feature, Pyramid Pooling Decoder, AuxLoss로 구성되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSPNet의 첫 번째 모듈은 Feature 모듈이며 Encoder 모듈로도 불린다. 입력 화상의 특징을 파악하는 것이 Feature 모듈의 목적이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSPNet의 두번 째 모듈은  Pyramid Pooling 모듈이다. PSPNet의 독창성을 보여주는 모듈이다. Pyramid Pooling 모듈로 해결하려는 문제는 '어떠한  픽셀의 물체 라벨을 구하려면 다양한 크기로 해당 픽셀 주변 정보가 필요'하다이다. \n",
    "하나의 픽셀만을 통해서는 해당 클래스의 라벨 값을 구분하기 어렵지만 해당 픽셀 주위를 점진적으로 확대한 특징량을 확인하면 소인지 돼지인지 알 수 있다는 것이다.\n",
    "\n",
    "Pyramid  Pooling은 네가지 크기의 특징량 맵을 준비한다. 화상 전첼르 차지하는 특징량, 화상 절반을 차지하는 특징량, 화상의 1/3을 차지하는 특징량, 화상의 1/6을 차지하는 특징량으로 Feature 모듈의 출력을 처리한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSPNet의 세번 째 모듈은  Decoder 모듈이다. 업샘플링 모듈이라고도 한다. Decoder 모듈의 목적은 두가지이다. 첫째, Pyramid Pooling 모듈의 출력을 텐서로 변환하는 것이다. 둘째, 변환된 텐서를 원 입력  화상 크기에 맞도록 변환하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원래대로라면 위 세 개의 모듈로 시맨틱  분할이 이루어지지만 PSPNet에서는 네트워크 결합  파라미터의 학습을 더 잘 수행하기 위해 AuxLoss 모듈을  준비한다. Aux란 Auxilary의 약어로 보조라는 뜻이다.  AuxLoss 모듈은 손실함수 계산을 보조한다. \n",
    "\n",
    "Feature 모듈로 중간 텐서를 빼내 입력 데이터로 한다. 이를 Decoder 모듈처럼  각 픽셀에 대응하는 물체 라벨 추정 클래스 분류를 실행한다. AuxLoss 모듈의 입력 데이터 크기는 1024by60by60, 출력은 Decoder 모듈의 클래스 분류와 마찬가지로 21by475by475이다.\n",
    "\n",
    "신경망 학습 시에는 AuxLoss 모듈의 출력과 Decoder 모듈의 출력을 모두 화상의 어노테이션 데이터로 대응시켜 손실 값을 계산한다. 게산 후 손실 값에 따른 오차 역전파 법을 실시하여 네트워크의 결합 파라미터를 갱신한다.\n",
    "\n",
    "학습 시에는 AuxLoss 모듈을 사용하지만 추론 시에는 AuxLoss 모듈의 출력은 사용하지 않고 Decoder 모듈의 출력만으로 시맨틱 분할을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSPNet 클래스 구현:\n",
    "\n",
    "Feature 모듈은 5개의 서브 네트워크 feature_conv, feature_res_1, feature_res_2, feature_dilated_res_1, feature_dilated_res_2로 하나의 서브 네트워크로 구성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 서브 네트워크 FeatureMap_convolution:\n",
    "\n",
    "서브 네트워크 FeatureMap_convolution은 단순히 합성곱, 배치 정규화, 최대 풀링으로 화상의 특징량을 추출하는 역할을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 서브 네트워크 ResidualBlockPSP:\n",
    "\n",
    "ResidualBlockPSP는 ResidualNetwork 신경망에서 사용되는 ResidualBlock 구조를 사용한다.\n",
    "ResidualBlockPSP는 bottleNeckPSP 클래스를 지나 bottleNeckIdentifyPSP 클래스를  여러 번 반복하여 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. bottleNeckPSP와 bottleNeckIdentifyPSP:\n",
    "\n",
    "bottleNeckPSP와 bottleNeckIdentifyPSP 두 클래스는 특징적인 네트워크 구조를 가졌으며 입력이 두 갈래로 나위어 처리된다. 이렇게 두 갈래로 나누어진 입력 아래쪽 루트를 스킵 결합이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝에서는 네트워크가 깊어지면 열화 문제가 발생한다. 열화문제를 피하기 위해 Residual Block의 입력 x를 그대로 출력하는 스킵 결합을 먼저 준비한다. 입력 그대로 출력(아래쪽)을 x, 스킵을 하지 않고 진행한 출력(위쪽)을 F(x)라 하면 Residual Block 출력 y는 y=x+F(X)가 된다.\n",
    "\n",
    "위쪽 경로의 각 유닛 학습 파라미터 값이 모두 0이라고 하면 Residual Block의 출력 y는 입력과 같은 x가 된다. 이 경우 Block이 여러 개 쌓여도 열화 문제를 피할 수 있다.\n",
    "\n",
    "Residual Block은 Block의 출력y를 학습시키는 것이 아니라 들어 온 입력 x는 그대로  스킵 결합으로 출력시키고 y-x, 즉 원하던 출력과 들어온 입려과의 잔차인 y-x=F(x)를 배우게 하는 전략이 Residual Block이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(PSPNet, self).__init__()\n",
    "\n",
    "        block_config = [3, 4, 6, 3]  \n",
    "        img_size = 475\n",
    "        img_size_8 = 60  \n",
    "\n",
    "        self.feature_conv = FeatureMap_convolution()\n",
    "        self.feature_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[0], in_channels=128, mid_channels=64, out_channels=256, stride=1, dilation=1)\n",
    "        self.feature_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[1], in_channels=256, mid_channels=128, out_channels=512, stride=2, dilation=1)\n",
    "        self.feature_dilated_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[2], in_channels=512, mid_channels=256, out_channels=1024, stride=1, dilation=2)\n",
    "        self.feature_dilated_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[3], in_channels=1024, mid_channels=512, out_channels=2048, stride=1, dilation=4)\n",
    "\n",
    "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[\n",
    "            6, 3, 2, 1], height=img_size_8, width=img_size_8)\n",
    "\n",
    "        self.decode_feature = DecodePSPFeature(\n",
    "            height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "        self.aux = AuxiliaryPSPlayers(\n",
    "            in_channels=1024, height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_conv(x)\n",
    "        x = self.feature_res_1(x)\n",
    "        x = self.feature_res_2(x)\n",
    "        x = self.feature_dilated_res_1(x)\n",
    "\n",
    "        output_aux = self.aux(x)  \n",
    "\n",
    "        x = self.feature_dilated_res_2(x)\n",
    "\n",
    "        x = self.pyramid_pooling(x)\n",
    "        output = self.decode_feature(x)\n",
    "\n",
    "        return (output, output_aux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNormRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNormRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        outputs = self.relu(x)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMap_convolution(nn.Module):\n",
    "    def __init__(self):\n",
    "     \n",
    "        super(FeatureMap_convolution, self).__init__()\n",
    "\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 3, 64, 3, 2, 1, 1, False\n",
    "        self.cbnr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 64, 3, 1, 1, 1, False\n",
    "        self.cbnr_2 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 128, 3, 1, 1, 1, False\n",
    "        self.cbnr_3 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbnr_1(x)\n",
    "        x = self.cbnr_2(x)\n",
    "        x = self.cbnr_3(x)\n",
    "        outputs = self.maxpool(x)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockPSP(nn.Sequential):\n",
    "    def __init__(self, n_blocks, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(ResidualBlockPSP, self).__init__()\n",
    "\n",
    "\n",
    "        self.add_module(\n",
    "            \"block1\",\n",
    "            bottleNeckPSP(in_channels, mid_channels,\n",
    "                          out_channels, stride, dilation)\n",
    "        )\n",
    "\n",
    "        for i in range(n_blocks - 1):\n",
    "            self.add_module(\n",
    "                \"block\" + str(i+2),\n",
    "                bottleNeckIdentifyPSP(\n",
    "                    out_channels, mid_channels, stride, dilation)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNorm(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNorm, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        outputs = self.batchnorm(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(bottleNeckPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.cb_residual = conv2DBatchNorm(\n",
    "            in_channels, out_channels, kernel_size=1, stride=stride, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = self.cb_residual(x)\n",
    "        return self.relu(conv + residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckIdentifyPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, stride, dilation):\n",
    "        super(bottleNeckIdentifyPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, in_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = x\n",
    "        return self.relu(conv + residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
