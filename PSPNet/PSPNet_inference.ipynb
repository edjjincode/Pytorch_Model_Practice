{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론:\n",
    "\n",
    "VOC 데이터셋 화상이 아니라 승마 화상에 대해 추론하며 어노테이션 화상을 한 장 사용한다.\n",
    "\n",
    "어노테이션 화상을 사용하는 두 가지 이유:\n",
    "\n",
    "1. 어노테이션 화상이 없으면 전처리 클래스의 함수가 제대로 작동하지 않는다. \n",
    "2. 어노테이션 화상에 색상 팔레트 정보를 추출하지 않으면 물체 라벨에 해당하는 색상 정보가 존재하지 않게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import make_datapath_list, DataTransform, VOCDataset\n",
    "\n",
    "\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
    "    rootpath=rootpath)\n",
    "\n",
    "color_mean = (0.485, 0.456, 0.406)\n",
    "color_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n",
    "    input_size=475, color_mean=color_mean, color_std=color_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pspnet import PSPNet\n",
    "\n",
    "net = PSPNet(n_classes=21)\n",
    "\n",
    "state_dict = torch.load(\"./weights/pspnet50_30.pth\",\n",
    "                        map_location={'cuda:0': 'cpu'})\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "print('ネットワーク設定完了：学習済みの重みをロードしました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index = 4\n",
    "\n",
    "\n",
    "image_file_path = val_img_list[img_index]\n",
    "img_original = Image.open(image_file_path)   \n",
    "img_width, img_height = img_original.size\n",
    "plt.imshow(img_original)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "anno_file_path = val_anno_list[img_index]\n",
    "anno_class_img = Image.open(anno_file_path)  \n",
    "p_palette = anno_class_img.getpalette()\n",
    "plt.imshow(anno_class_img)\n",
    "plt.show()\n",
    "\n",
    "#PSPNet으로 추론\n",
    "net.eval()\n",
    "img, anno_class_img = val_dataset.__getitem__(img_index)\n",
    "x = img.unsqueeze(0)  \n",
    "outputs = net(x)\n",
    "y = outputs[0]  # AuxLoss\n",
    "\n",
    "# PSPNet 출력으로 최대 클래스를 구하여 색상 팔레트 형식으로 화상 크기를 원래대로 되돌린다.\n",
    "y = y[0].detach().numpy() \n",
    "y = np.argmax(y, axis=0)\n",
    "anno_class_img = Image.fromarray(np.uint8(y), mode=\"P\")\n",
    "anno_class_img = anno_class_img.resize((img_width, img_height), Image.NEAREST)\n",
    "anno_class_img.putpalette(p_palette)\n",
    "plt.imshow(anno_class_img)\n",
    "plt.show()\n",
    "\n",
    "#화상을 투과시켜 겹친다.\n",
    "trans_img = Image.new('RGBA', anno_class_img.size, (0, 0, 0, 0))\n",
    "anno_class_img = anno_class_img.convert('RGBA') \n",
    "\n",
    "for x in range(img_width):\n",
    "    for y in range(img_height):\n",
    "    \n",
    "        pixel = anno_class_img.getpixel((x, y))\n",
    "        r, g, b, a = pixel\n",
    "\n",
    "        if pixel[0] == 0 and pixel[1] == 0 and pixel[2] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            trans_img.putpixel((x, y), (r, g, b, 200))\n",
    "\n",
    "result = Image.alpha_composite(img_original.convert('RGBA'), trans_img)\n",
    "plt.imshow(result)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시맨틱 분할의 정확성을 높이려면 학습 에폭 수를 늘려야 한다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
