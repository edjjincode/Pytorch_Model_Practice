{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import SSD\n",
    "\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "ssd_cfg = {\n",
    "    'num_classes' : 21,\n",
    "    'input_size': 300,\n",
    "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],\n",
    "    'features_maps': [38, 19, 10, 5, 3, 1],\n",
    "    'steps': [8, 16, 32, 64, 100, 300],\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],\n",
    "    'max_sizes': [60,111, 162, 213, 264, 315],\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3]. [2], [2]]\n",
    "}\n",
    "\n",
    "net = SSD(phase = \"inference\", cfg = ssd_cfg)\n",
    "\n",
    "net_weights = torch.load('./weights/ssd300_50.pth',\n",
    "                         map_location={'cuda:0': 'cpu'})\n",
    "\n",
    "net.load_state_dict(net_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import DataTransform\n",
    "\n",
    "image_file_path = \"./data/cowboy-757575_640.jpg\"\n",
    "img = cv2.imread(image_file_path)\n",
    "height, width, channels = img.Shape\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "color_mean(104, 117, 123)\n",
    "input_size = 300\n",
    "transform = DataTransform(input_size, color_mean)\n",
    "\n",
    "phase = \"val\"\n",
    "img_transformed, boxes, labels = transform(\n",
    "    img, phase, \"\", \"\"\n",
    ")\n",
    "img = torch.from_numpy(img_transformed[:, :, (2, 1, 0)]).permute(2, 0, 1)\n",
    "\n",
    "net.eval()\n",
    "x = img.unsqueeze(0)\n",
    "detections = net(x)\n",
    "\n",
    "print(detections.shape)\n",
    "print(detections)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
