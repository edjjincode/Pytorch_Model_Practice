{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 해당 장에서는 전이학습 및 Pytorch를 활용해서 딥러닝을 돌리는 방법에 대해서 배우는 시간을 가졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path as osp\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 폴더 경로 정하기(Making Folder and Directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "save_path = os.path.join(data_dir, \"imagenet_class_index.json\")\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    urllib.request.urlretrieve(url, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
    "save_path = os.path.join(data_dir, \"hymenoptera_data.zip\")\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    urllib.request.urlretrieve(url, save_path)\n",
    "\n",
    "    zip = zipfile.ZipFile(save_path)\n",
    "    zip.extractall(data_dir)  \n",
    "    zip.close()  \n",
    "\n",
    "    os.remove(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 이미지를 변환하는 클래스를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    \n",
    "    def __init__(self, resize, mean, std):\n",
    "        self.data_transform = {\n",
    "            \"train\" :  transforms.Compose([\n",
    "                transforms.RandomResizedCrop(\n",
    "                    resize, scale = (0.5, 1.0)\n",
    "                ),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ]),\n",
    "            \"val\" : transforms.Compose([\n",
    "                transforms.Resize(resize),\n",
    "                transforms.CenterCrop(resize),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "        }\n",
    "    def __call__(self, img, phase = \"train\"):\n",
    "        return self.data_transform[phase](img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__call__ 메서드는 객체를 호출 가능하게 만든다. ImageTransform 객체가 이미지와 선택적인 인자와 함께 호출될 때, self.data_transform[phase](img)가 리턴된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train과 Val 데이터 셋의 경로를 지정한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list(phase = \"train\"):\n",
    "    \n",
    "    rootpath = \"./data/hymenoptera_data/\"\n",
    "    target_path = osp.join(rootpath+phase+'/**/*.jpg')\n",
    "    print(target_path)\n",
    "\n",
    "    path_list = []  \n",
    "\n",
    "    for path in glob.glob(target_path):\n",
    "        path_list.append(path)\n",
    "\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/hymenoptera_data/train/**/*.jpg\n",
      "./data/hymenoptera_data/val/**/*.jpg\n"
     ]
    }
   ],
   "source": [
    "train_list = make_datapath_list(phase=\"train\")\n",
    "val_list = make_datapath_list(phase=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HymenopteraDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, file_list, transform = None, phase = \"train\"):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    # __getitem__을 작동시킬려고 하려면 dataset(index)\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        img_transformed = self.transform(img, self.phase)\n",
    "\n",
    "        if self.phase == \"train\":\n",
    "            label = img_path[30:34]\n",
    "        elif self.phase == \"val\":\n",
    "            label = img_path[28:32]\n",
    "\n",
    "        if label == \"ants\":\n",
    "            label = 0\n",
    "        elif label == \"bees\":\n",
    "            label = 1\n",
    "        \n",
    "        return img_transformed, label\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "train_dataset = HymenopteraDataset(\n",
    "    file_list = train_list, transform = ImageTransform(size, mean, std), phase = 'train') \n",
    "\n",
    "val_dataset = HymenopteraDataset(\n",
    "    file_list = val_list, transform = ImageTransform(size, mean, std), phase = 'val')\n",
    "\n",
    "\n",
    "index = 0\n",
    "print(train_dataset.__getitem__(index)[0].size())\n",
    "print(train_dataset.__getitem__(index)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DataLoader를 통해 데이터 셋을 텐서 형태로 변환해주는 작업을 거친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size = batch_size, shuffle = True\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "\n",
    "batch_iterator = iter(dataloaders_dict[\"train\"])  \n",
    "inputs, labels = next(\n",
    "    batch_iterator)  \n",
    "print(inputs.size())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 전이학습 할 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존에 사용했던 전이 학습층을 사용해서 학습을 진행함\n",
    "use_pretrained = True\n",
    "net = models.vgg16(pretrained = use_pretrained)\n",
    "\n",
    "# 마지막 fc-layer의 input을 4096, output을 2개로 나올 수 있도록 함(vgg-net의 6번째 층)\n",
    "net.classifier[6] = nn.Linear(in_features = 4096, out_features = 2)\n",
    "\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 목적적함수 정의:\n",
    "\n",
    "트레인을 하기 전에 목적함수(Loss Function)을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 전이학습을 시킬 net 모델(VGGNET)의 일부 파라미터를 업데이트 하는 과정을 거친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "\n",
    "update_param_names = ['classifier.6.weight', 'classifier.6.bias']\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    if name in update_param_names:\n",
    "        param.requires_grad = True\n",
    "        params_to_update.append(param)\n",
    "        print(name)\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 업데이트한 파라미터를 반영하여 옵티마이저를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(params = params_to_update, lr = 0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "            \n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "\n",
    "            if (epoch == 0) and (phase == \"train\"):\n",
    "                continue\n",
    "\n",
    "            for inputs, labels in tqdm(dataloaders_dict[phase]):# 미니 배치를 가져오고 있다.\n",
    "\n",
    "                optimizer.zero_grad()# 옵티마이저의 그라디언트를 초기화 한다\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):# 학습 단계에서만 그라디언트를 계산하도록 한다. 검증 시에는 경사를 계산할 필요가 없다. 파이토치에서 학습과 검증으로 네트워크 모드를 전환하는 것은 드롭아웃 층과 같이 학습 및 검증에 동작이 서로 다른 층이 있기 때문이다.\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()#학습 단계에서 역전파를 수행하고\n",
    "                        optimizer.step()#옵티마이저를 사용하여 가중치를 업데이트한다.\n",
    "\n",
    "                    epoch_loss += loss.item() * inputs.size(0) # 에폭 손실을 업데이트 한다.\n",
    "                    # epoch_loss는 현재까지의 누적 손실 값을 나타내며, 각 미니배치의 손실 값을 미니배치의 크기로 가중하여 더해줍니다. 이는 각 미니배치의 손실을 모두 더한 후에 전체 데이터셋의 크기로 나누어 평균 손실 값을 계산하는데 사용됩니다.\n",
    "\n",
    "                    epoch_corrects += torch.sum(preds == labels.data) #정확하게 예측된 수를 업데이트 한다\n",
    "            \n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "옵티마이저의 그라디언트를 초기화 하는 이유는 새로운 미니배치를 사용하여 새로운 경사하강 단계를 시작하기 전에 이전 단계의 그라디언트가 현재 단계에 영향을 미치지 않도록 하기 위해서이다. (요약) 미니 배치 간에 그라디언트 영향을 주지 않기 때문이다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
